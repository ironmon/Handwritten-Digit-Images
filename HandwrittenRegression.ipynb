{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "手写数字识别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt   #画图库\n",
    "from sklearn import datasets, metrics  #sklearn机器学习库\n",
    "from sklearn.linear_model import LogisticRegression    #逻辑斯蒂回归库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ..., 10.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ..., 16.,  9.,  0.],\n",
       "        ...,\n",
       "        [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "        [ 0.,  0.,  2., ..., 12.,  0.,  0.],\n",
       "        [ 0.,  0., 10., ..., 12.,  1.,  0.]]),\n",
       " 'target': array([0, 1, 2, ..., 8, 9, 8]),\n",
       " 'frame': None,\n",
       " 'feature_names': ['pixel_0_0',\n",
       "  'pixel_0_1',\n",
       "  'pixel_0_2',\n",
       "  'pixel_0_3',\n",
       "  'pixel_0_4',\n",
       "  'pixel_0_5',\n",
       "  'pixel_0_6',\n",
       "  'pixel_0_7',\n",
       "  'pixel_1_0',\n",
       "  'pixel_1_1',\n",
       "  'pixel_1_2',\n",
       "  'pixel_1_3',\n",
       "  'pixel_1_4',\n",
       "  'pixel_1_5',\n",
       "  'pixel_1_6',\n",
       "  'pixel_1_7',\n",
       "  'pixel_2_0',\n",
       "  'pixel_2_1',\n",
       "  'pixel_2_2',\n",
       "  'pixel_2_3',\n",
       "  'pixel_2_4',\n",
       "  'pixel_2_5',\n",
       "  'pixel_2_6',\n",
       "  'pixel_2_7',\n",
       "  'pixel_3_0',\n",
       "  'pixel_3_1',\n",
       "  'pixel_3_2',\n",
       "  'pixel_3_3',\n",
       "  'pixel_3_4',\n",
       "  'pixel_3_5',\n",
       "  'pixel_3_6',\n",
       "  'pixel_3_7',\n",
       "  'pixel_4_0',\n",
       "  'pixel_4_1',\n",
       "  'pixel_4_2',\n",
       "  'pixel_4_3',\n",
       "  'pixel_4_4',\n",
       "  'pixel_4_5',\n",
       "  'pixel_4_6',\n",
       "  'pixel_4_7',\n",
       "  'pixel_5_0',\n",
       "  'pixel_5_1',\n",
       "  'pixel_5_2',\n",
       "  'pixel_5_3',\n",
       "  'pixel_5_4',\n",
       "  'pixel_5_5',\n",
       "  'pixel_5_6',\n",
       "  'pixel_5_7',\n",
       "  'pixel_6_0',\n",
       "  'pixel_6_1',\n",
       "  'pixel_6_2',\n",
       "  'pixel_6_3',\n",
       "  'pixel_6_4',\n",
       "  'pixel_6_5',\n",
       "  'pixel_6_6',\n",
       "  'pixel_6_7',\n",
       "  'pixel_7_0',\n",
       "  'pixel_7_1',\n",
       "  'pixel_7_2',\n",
       "  'pixel_7_3',\n",
       "  'pixel_7_4',\n",
       "  'pixel_7_5',\n",
       "  'pixel_7_6',\n",
       "  'pixel_7_7'],\n",
       " 'target_names': array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]),\n",
       " 'images': array([[[ 0.,  0.,  5., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0., 13., ..., 15.,  5.,  0.],\n",
       "         [ 0.,  3., 15., ..., 11.,  8.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  4., 11., ..., 12.,  7.,  0.],\n",
       "         [ 0.,  2., 14., ..., 12.,  0.,  0.],\n",
       "         [ 0.,  0.,  6., ...,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0., ...,  5.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  9.,  0.,  0.],\n",
       "         [ 0.,  0.,  3., ...,  6.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "         [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ..., 10.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0., ..., 12.,  0.,  0.],\n",
       "         [ 0.,  0.,  3., ..., 14.,  0.,  0.],\n",
       "         [ 0.,  0.,  8., ..., 16.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  9., 16., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  3., 13., ..., 11.,  5.,  0.],\n",
       "         [ 0.,  0.,  0., ..., 16.,  9.,  0.]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0.,  0.,  1., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0., 13., ...,  2.,  1.,  0.],\n",
       "         [ 0.,  0., 16., ..., 16.,  5.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0., 16., ..., 15.,  0.,  0.],\n",
       "         [ 0.,  0., 15., ..., 16.,  0.,  0.],\n",
       "         [ 0.,  0.,  2., ...,  6.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  2., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0., 14., ..., 15.,  1.,  0.],\n",
       "         [ 0.,  4., 16., ..., 16.,  7.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0.,  0., ..., 16.,  2.,  0.],\n",
       "         [ 0.,  0.,  4., ..., 16.,  2.,  0.],\n",
       "         [ 0.,  0.,  5., ..., 12.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0., 10., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  2., 16., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0., 15., ..., 15.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  4., 16., ..., 16.,  6.,  0.],\n",
       "         [ 0.,  8., 16., ..., 16.,  8.,  0.],\n",
       "         [ 0.,  1.,  8., ..., 12.,  1.,  0.]]]),\n",
       " 'DESCR': \".. _digits_dataset:\\n\\nOptical recognition of handwritten digits dataset\\n--------------------------------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 5620\\n    :Number of Attributes: 64\\n    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\\n    :Missing Attribute Values: None\\n    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\\n    :Date: July; 1998\\n\\nThis is a copy of the test set of the UCI ML hand-written digits datasets\\nhttps://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\\n\\nThe data set contains images of hand-written digits: 10 classes where\\neach class refers to a digit.\\n\\nPreprocessing programs made available by NIST were used to extract\\nnormalized bitmaps of handwritten digits from a preprinted form. From a\\ntotal of 43 people, 30 contributed to the training set and different 13\\nto the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\\n4x4 and the number of on pixels are counted in each block. This generates\\nan input matrix of 8x8 where each element is an integer in the range\\n0..16. This reduces dimensionality and gives invariance to small\\ndistortions.\\n\\nFor info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\\nT. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\\nL. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\\n1994.\\n\\n.. topic:: References\\n\\n  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\\n    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\\n    Graduate Studies in Science and Engineering, Bogazici University.\\n  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\\n  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\\n    Linear dimensionalityreduction using relevance weighted LDA. School of\\n    Electrical and Electronic Engineering Nanyang Technological University.\\n    2005.\\n  - Claudio Gentile. A New Approximate Maximal Margin Classification\\n    Algorithm. NIPS. 2000.\"}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits = datasets.load_digits()\n",
    "digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "samples = list(zip(digits.images, digits.target))\n",
    "for id, (img, label) in enumerate(samples[:4]):\n",
    "    plt.subplot(1, 4, id + 1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img, cmap=plt.cm.gray_r, interpolation='nearest')     #灰度图\n",
    "    plt.title('Label: %i' % label)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#有n个图像\n",
    "n = len(digits.images)\n",
    "# convert 2D image to 1D feature（nx8x8->nx64），方便处理\n",
    "data = digits.images.reshape(n, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Build Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(C = 1e5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=100000.0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#use first half as training, second half as validation\n",
    "model.fit(data[:n//2], digits.target[:n//2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = digits.target[n//2:]\n",
    "pred = model.predict(data[n//2:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将预测结果与正确答案进行比较"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[84,  0,  0,  0,  1,  0,  3,  0,  0,  0],\n",
       "       [ 1, 81,  0,  1,  1,  1,  1,  0,  1,  4],\n",
       "       [ 0,  0, 86,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0, 77,  0,  3,  0,  2,  9,  0],\n",
       "       [ 0,  1,  0,  0, 82,  0,  6,  0,  0,  3],\n",
       "       [ 0,  1,  1,  0,  0, 84,  1,  0,  1,  3],\n",
       "       [ 0,  1,  0,  0,  0,  0, 90,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  1,  0,  0, 85,  0,  3],\n",
       "       [ 0,  3,  0,  0,  1,  3,  1,  0, 79,  1],\n",
       "       [ 1,  0,  0,  0,  0,  2,  0,  1,  2, 86]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(answer, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#accuracy\n",
    "#sum(1 for a, b in zip(answer, pred) if a == b / len(answer) * 100.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "打印几个预测的例子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "samples = list(zip(digits.images[n//2:], pred))\n",
    "for id, (img, label) in enumerate(samples[:4]):\n",
    "    plt.subplot(1, 4, id + 1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img, cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.title('Predict: %i' % label)\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
